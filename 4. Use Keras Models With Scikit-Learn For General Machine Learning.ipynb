{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Keras Models With Scikit-Learn For General Machine Learning\n",
    "The scikit-learn library is the most popular library for general machine learning in Python.\n",
    "In this lesson you will discover how you can use deep learning models from Keras with the\n",
    "scikit-learn library in Python. After completing this lesson you will know:\n",
    "1. How to wrap a Keras model for use with the scikit-learn machine learning library.\n",
    "2. How to easily evaluate Keras models using cross validation in scikit-learn.\n",
    "3. How to tune Keras model hyperparameters using grid search in scikit-learn.\n",
    "Let’s get started.\n",
    "\n",
    "## 1.1 Overview\n",
    "Keras is a popular library for deep learning in Python, but the focus of the library is deep\n",
    "learning. In fact it strives for minimalism, focusing on only what you need to quickly and simply\n",
    "define and build deep learning models. The scikit-learn library in Python is built upon the\n",
    "SciPy stack for efficient numerical computation. It is a fully featured library for general purpose\n",
    "machine learning and provides many utilities that are useful in the development of deep learning\n",
    "models. Not least:\n",
    "1. Evaluation of models using resampling methods like k-fold cross validation.\n",
    "2.  Efficient search and evaluation of model hyperparameters.\n",
    "\n",
    "The Keras library provides a convenient wrapper for deep learning models to be used as\n",
    "classification or regression estimators in scikit-learn. In the next sections we will work through\n",
    "examples of using the KerasClassifier wrapper for a classification neural network created\n",
    "in Keras and used in the scikit-learn library. The test problem is the Pima Indians onset of\n",
    "diabetes classification dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Evaluate Models with Cross Validation\n",
    "The KerasClassifier and KerasRegressor classes in Keras take an argument build fn which\n",
    "is the name of the function to call to create your model. You must define a function called\n",
    "whatever you like that defines your model, compiles it and returns it. In the example below\n",
    "we define a function create model() that create a simple multilayer neural network for the\n",
    "problem.\n",
    "We pass this function name to the KerasClassifier class by the build fn argument.\n",
    "We also pass in additional arguments of nb epoch=150 and batch size=10. These are auto-\n",
    "matically bundled up and passed on to the fit() function which is called internally by the\n",
    "KerasClassifier class. In this example we use the scikit-learn StratifiedKFold to perform\n",
    "10-fold stratified cross validation. This is a resampling technique that can provide a robust\n",
    "estimate of the performance of a machine learning model on unseen data. We use the scikit-learn\n",
    "function cross val score() to evaluate our model using the cross validation scheme and print\n",
    "the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746069723253\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
    "# Evaluate A Neural Network Using scikit-learn.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init= 'uniform' , activation= 'relu' ))\n",
    "    model.add(Dense(8, init= 'uniform' , activation= 'relu' ))\n",
    "    model.add(Dense(1, init= 'uniform' , activation= 'sigmoid' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10, verbose=0)\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(y=Y, n_folds=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example displays the skill of the model for each epoch. A total of 10 models\n",
    "are created and evaluated and the final average accuracy is displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that when the Keras model is wrapped that estimating model accuracy can be\n",
    "greatly streamlined, compared to the manual enumeration of cross validation folds performed in\n",
    "the previous lesson.\n",
    "\n",
    "#### 1.3 Grid Search Deep Learning Model Parameters\n",
    "The previous example showed how easy it is to wrap your deep learning model from Keras\n",
    "and use it in functions from the scikit-learn library. In this example we go a step further. We\n",
    "already know we can provide arguments to the fit() function. The function that we specify to\n",
    "the build fn argument when creating the KerasClassifier wrapper can also take arguments.\n",
    "We can use these arguments to further customize the construction of the model.\n",
    "In this example we use a grid search to evaluate different configurations for our neural\n",
    "network model and report on the combination that provides the best estimated performance.\n",
    "The create model() function is defined to take two arguments optimizer and init, both of\n",
    "which must have default values. This will allow us to evaluate the effect of using different\n",
    "optimization algorithms and weight initialization schemes for our network. After creating our\n",
    "model, we define arrays of values for the parameter we wish to search, specifically:\n",
    "1. Optimizers for searching different weight values.\n",
    "2. Initializers for preparing the network weights using different schemes.\n",
    "3. Number of epochs for training the model for different number of exposures to the training\n",
    "dataset.\n",
    "4. Batches for varying the number of samples before weight updates.\n",
    "\n",
    "The options are specified into a dictionary and passed to the configuration of the GridSearchCV\n",
    "scikit-learn class. This class will evaluate a version of our neural network model for each combi-\n",
    "nation of parameters (2 × 3 × 3 × 3) for the combinations of optimizers, initializations, epochs\n",
    "and batches). Each combination is then evaluated using the default of 3-fold stratified cross\n",
    "validation.\n",
    "\n",
    "That is a lot of models and a lot of computation. This is not a scheme that you want to\n",
    "use lightly because of the time it will take to compute. It may be useful for you to design\n",
    "small experiments with a smaller subset of your data that will complete in a reasonable time.\n",
    "This experiment is reasonable in this case because of the small network and the small dataset\n",
    "(less than 1,000 instances and 9 attributes). Finally, the performance and combination of\n",
    "configurations for the best model are displayed, followed by the performance of all combinations\n",
    "of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset with grid search via sklearn\n",
    "# Grid Search Neural Network Parameters Using scikit-learn.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer= 'rmsprop' , init= 'glorot_uniform' ):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init= 'uniform' , activation= 'relu' ))\n",
    "    model.add(Dense(8, init= 'uniform' , activation= 'relu' ))\n",
    "    model.add(Dense(1, init= 'uniform' , activation= 'sigmoid' ))\n",
    "    # Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform' , 'normal', 'uniform']\n",
    "epochs = numpy.array([50, 100, 150])\n",
    "batches = numpy.array([5, 10, 20])\n",
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of Grid Search Neural Network Parameters Using scikit-learn.\n",
    "\n",
    "#### 1.4 Summary\n",
    "In this lesson you discovered how you can wrap your Keras deep learning models and use them\n",
    "in the scikit-learn general machine learning library. You learned:\n",
    "1. Specifically how to wrap Keras models so that they can be used with the scikit-learn\n",
    "machine learning library.\n",
    "2. How to use a wrapped Keras model as part of evaluating model performance in scikit-learn.\n",
    "3. How to perform hyperparameter tuning in scikit-learn using a wrapped Keras model.\n",
    "\n",
    "You can see that using scikit-learn for standard machine learning operations such as model\n",
    "evaluation and model hyperparameter optimization can save a lot of time over implementing\n",
    "these schemes yourself.\n",
    "\n",
    "### Next\n",
    "You now know how to best integrate your Keras models into the scikit-learn machine learning\n",
    "library. Now it is time to put your new skills to the test. Over the next few chapters you\n",
    "will practice developing neural network models in Keras end-to-end, starting with a multiclass\n",
    "classification problem next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
