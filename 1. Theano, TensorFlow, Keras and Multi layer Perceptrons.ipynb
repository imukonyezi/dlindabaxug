{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano, TensorFlow, Keras and Multi layer Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 What is Theano?\n",
    "Theano is an open source project released under the BSD license and was developed by the LISA\n",
    "(now MILA http://mila.umontreal.ca/) group at the University of Montreal, Quebec, Canada.\n",
    "It is named after a Greek mathematician. At it’s heart Theano is a compiler for mathematical\n",
    "expressions in Python. It knows how to take your structures and turn them into very efficient\n",
    "code that uses NumPy, efficient native libraries like BLAS and native code to run as fast as\n",
    "possible on CPUs or GPUs.\n",
    "\n",
    "It uses a host of clever code optimizations to squeeze as much performance as possible from\n",
    "your hardware. If you are into the nitty-gritty of mathematical optimizations in code, check out\n",
    "this interesting list (http://deeplearning.net/software/theano/optimizations.html#optimizations) . The actual syntax of Theano expressions is symbolic, which can be off\n",
    "putting to beginners. Specifically, expression are defined in the abstract sense, compiled and\n",
    "later actually used to make calculations.\n",
    "\n",
    "Theano was specifically designed to handle the types of computation required for large\n",
    "neural network algorithms used in deep learning. It was one of the first libraries of its kind\n",
    "(development started in 2007) and is considered an industry standard for deep learning research\n",
    "and development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 How to Install Theano\n",
    "Theano provides extensive installation instructions for the major operating systems: Windows,\n",
    "OS X and Linux. Read the Installing Theano guide for your platform (http://deeplearning.net/software/theano/install.html) . Theano assumes a\n",
    "working Python 2 or Python 3 environment with SciPy. There are ways to make the installation\n",
    "easier, such as using Anaconda (https://www.continuum.io/downloads) to quickly setup Python and SciPy on your machine as well\n",
    "as using Docker images. With a working Python and SciPy environment, it is relatively\n",
    "straightforward to install Theano using pip, for example:\n",
    "\n",
    "``` sudo pip install Theano ```\n",
    "\n",
    "New releases of Theano may be announced and you will want to update to get any bug fixes\n",
    "and efficiency improvements. You can upgrade Theano using pip as follows:\n",
    "\n",
    "``` sudo pip install --upgrade --no-deps theano ```\n",
    "\n",
    "You may want to use the bleeding edge version of Theano checked directly out of GitHub.\n",
    "This may be required for some wrapper libraries that make use of bleeding edge API changes.\n",
    "You can install Theano directly from a GitHub checkout as follows:\n",
    "\n",
    "``` sudo pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git ```\n",
    "\n",
    "You are now ready to run Theano on your CPU, which is just fine for the development of\n",
    "small models. Large models may run slowly on the CPU. If you have a Nvidia GPU, you may\n",
    "want to look into configuring Theano to use your GPU. There is a wealth of documentation of\n",
    "the Theano homepage for further configuring the library.\n",
    "\n",
    "### 1.3 Simple Theano Example\n",
    "In this section we demonstrate a simple Python script that gives you a flavor of Theano. In this\n",
    "example we define two symbolic floating point variables a and b. We define an expression that\n",
    "uses these variables (c = a + b). We then compile this symbolic expression into a function using\n",
    "Theano that we can use later. Finally, we use our compiled expression by plugging in some real\n",
    "values and performing the calculation using efficient compiled Theano code under the covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# Example of Theano library\n",
    "import theano\n",
    "from theano import tensor\n",
    "# declare two symbolic floating-point scalars\n",
    "a = tensor.dscalar()\n",
    "b = tensor.dscalar()\n",
    "# create a simple symbolic expression\n",
    "c = a + b\n",
    "# convert the expression into a callable object that takes (a,b) and computes c\n",
    "f = theano.function([a,b], c)\n",
    "# bind 1.5 to ✬ a ✬ , 2.5 to ✬ b ✬ , and evaluate ✬ c ✬\n",
    "result = f(1.5, 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints the output 4, which matches our expectation that 1.5 + 2.5 = 4.0.\n",
    "This is a useful example as it gives you a flavor for how a symbolic expression can be defined,\n",
    "compiled and used. You can see how this may be scaled up to large vector and matrix operations\n",
    "required for deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Extensions and Wrappers for Theano\n",
    "If you are new to deep learning you do not have to use Theano directly. In fact, you are highly\n",
    "encouraged to use one of many popular Python projects that make Theano a lot easier to use\n",
    "for deep learning. These projects provide data structures and behaviors in Python, specifically\n",
    "designed to quickly and reliably create deep learning models whilst ensuring that fast and\n",
    "efficient models are created and executed by Theano under the covers. The amount of Theano\n",
    "syntax exposed by the libraries varies.\n",
    "\n",
    "Keras is a wrapper library that hides Theano completely and provides a very simple API to\n",
    "work with to create deep learning models. It hides Theano so well, that it can in fact run as a\n",
    "wrapper for another popular foundation framework called TensorFlow (discussed next)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 More Theano Resources\n",
    "Looking for some more resources on Theano? Take a look at some of the following.\n",
    "1. Theano Official Homepage\n",
    "http://deeplearning.net/software/theano/\n",
    "2. Theano GitHub Repository\n",
    "https://github.com/Theano/Theano/\n",
    "3. Theano: A CPU and GPU Math Compiler in Python (2010)\n",
    "http://www.iro.umontreal.ca/~lisa/pointeurs/theano_scipy2010.pdf\n",
    "4. List of Libraries Built on Theano\n",
    "https://github.com/Theano/Theano/wiki/Related-projects\n",
    "5. List of Theano configuration options\n",
    "http://deeplearning.net/software/theano/library/config.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Summary\n",
    "In this lesson you discovered the Theano Python library for efficient numerical computation.\n",
    "You learned:\n",
    "1. Theano is a foundation library used for deep learning research and development.\n",
    "2. Deep learning models can be developed directly in Theano if desired.\n",
    "3. The development and evaluation of deep learning models is easier with wrapper libraries like Keras.\n",
    "\n",
    "### Next\n",
    "You now know about the Theano library for numerical computation in Python. In the next\n",
    "lesson you will discover the TensorFlow library released by Google that attempts to offer the\n",
    "same capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Introduction to TensorFlow\n",
    "TensorFlow is a Python library for fast numerical computing created and released by Google.\n",
    "It is a foundation library that can be used to create deep learning models directly or by using\n",
    "wrapper libraries that simplify the process built on top of TensorFlow. After completing this\n",
    "lesson you will know:\n",
    "1. About the TensorFlow library for Python.\n",
    "2. How to define, compile and evaluate a simple symbolic expression in TensorFlow.\n",
    "3. Where to go to get more information on the Library.\n",
    "\n",
    "Let’s get started.\n",
    "\n",
    "### 2.2 What is TensorFlow?\n",
    "TensorFlow is an open source library for fast numerical computing. It was created and is\n",
    "maintained by Google and released under the Apache 2.0 open source license. The API is\n",
    "nominally for the Python programming language, although there is access to the underlying\n",
    "C++ API. Unlike other numerical libraries intended for use in Deep Learning like Theano,\n",
    "TensorFlow was designed for use both in research and development and in production systems,\n",
    "not least RankBrain in Google search (https://en.wikipedia.org/wiki/RankBrain) and the fun DeepDream project (https://en.wikipedia.org/wiki/DeepDream) . It an run on single\n",
    "CPU systems, GPUs as well as mobile devices and large scale distributed systems of hundreds\n",
    "of machines.\n",
    "\n",
    "### 2.3 How to Install TensorFlow\n",
    "Installation of TensorFlow is straightforward if you already have a Python SciPy environment.\n",
    "TensorFlow works with Python 2.7 and Python 3.3+. With a working Python and SciPy environment, it is relatively straightforward to install TensorFlow using pip There are a number\n",
    "of different distributions of TensorFlow, customized for different environments, therefore to\n",
    "install TensorFlow you can follow the Download and Setup instructions (https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html) on the TensorFlow\n",
    "website.\n",
    "\n",
    "### 2.4 Your First Examples in TensorFlow\n",
    "Computation is described in terms of data flow and operations in the structure of a directed\n",
    "graph.\n",
    "1. Nodes: Nodes perform computation and have zero or more inputs and outputs. Data that\n",
    "moves between nodes are known as tensors, which are multi-dimensional arrays of real\n",
    "values.\n",
    "2. Edges: The graph defines the flow of data, branching, looping and updates to state.\n",
    "Special edges can be used to synchronize behavior within the graph, for example waiting\n",
    "for computation on a number of inputs to complete.\n",
    "3. Operation: An operation is a named abstract computation which can take input attributes\n",
    "and produce output attributes. For example, you could define an add or multiply operation.\n",
    "\n",
    "### 2.5 Simple TensorFlow Example\n",
    "In this section we demonstrate a simple Python script that gives you a flavor of TensorFlow. In\n",
    "this example we define two symbolic floating point variables a and b. We define an expression\n",
    "that uses these variables (c = a + b). This is the same example used in the previous chapter that\n",
    "introduced Theano. We then compile this symbolic expression into a function using TensorFlow\n",
    "that we can use later. Finally, we use our complied expression by plugging in some real values\n",
    "and performing the calculation using efficient compiled TensorFlow code under the covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# Example of TensorFlow library\n",
    "import tensorflow as tf\n",
    "# declare two symbolic floating-point scalars\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "# create a simple symbolic expression using the add function\n",
    "add = tf.add(a, b)\n",
    "# bind 1.5 to ✬ a ✬ , 2.5 to ✬ b ✬ , and evaluate ✬ c ✬\n",
    "sess = tf.Session()\n",
    "binding = {a: 1.5, b: 2.5}\n",
    "c = sess.run(add, feed_dict=binding)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 More Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your TensorFlow installation comes with a number of Deep Learning models that you can use\n",
    "and experiment with directly. Firstly, you need to find out where TensorFlow was installed on\n",
    "your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda2/lib/python2.7/site-packages/tensorflow\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import inspect\n",
    "import tensorflow\n",
    "print(os.path.dirname(inspect.getfile(tensorflow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to this directory and take note of the models/image/ .subdirectory. Included are a number\n",
    "of deep learning models with tutorial-like comments, such as:\n",
    "- Multi-threaded word2vec mini-batched skip-gram model.\n",
    "- Multi-threaded word2vec unbatched skip-gram model.\n",
    "- CNN for the CIFAR-10 network.\n",
    "- Simple, end-to-end, LeNet-5-like convolutional MNIST model example.\n",
    "- Sequence-to-sequence model with an attention mechanism.\n",
    "Also check the examples directory as it contains an example using the MNIST dataset.\n",
    "There is also an excellent list of tutorials on the main TensorFlow website 4 . They show how\n",
    "to use different network types, different datasets and how to use the framework in various\n",
    "different ways. Finally, there is the TensorFlow playground 5 where you can experiment with\n",
    "small networks right in your web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Introduction to Keras\n",
    "Two of the top numerical platforms in Python that provide the basis for deep learning research\n",
    "and development are Theano and TensorFlow. Both are very powerful libraries, but both can\n",
    "be difficult to use directly for creating deep learning models. In this lesson you will discover\n",
    "the Keras Python library that provides a clean and convenient way to create a range of deep\n",
    "learning models on top of Theano or TensorFlow. After completing this lesson you will know:\n",
    "- About the Keras Python library for deep learning.\n",
    "- How to configure Keras for Theano or TensorFlow.\n",
    "- The standard idiom for creating models with Keras.\n",
    "Let’s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 What is Keras?\n",
    "Keras is a minimalist Python library for deep learning that can run on top of Theano or\n",
    "TensorFlow. It was developed to make developing deep learning models as fast and easy as\n",
    "possible for research and development. It runs on Python 2.7 or 3.5 and can seamlessly execute\n",
    "on GPUs and CPUs given the underlying frameworks. It is released under the permissive MIT\n",
    "license. Keras was developed and maintained by Fran ̧cois Chollet, a Google engineer using four\n",
    "guiding principles:\n",
    "- Modularity: A model can be understood as a sequence or a graph alone. All the concerns of a deep learning model are discrete components that can be combined in arbitrary ways.\n",
    "- Minimalism: The library provides just enough to achieve an outcome, no frills and maximizing readability.\n",
    "- Extensibility: New components are intentionally easy to add and use within the framework, intended for developers to trial and explore new ideas.\n",
    "- Python: No separate model files with custom file formats. Everything is native Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 How to Install Keras\n",
    "Keras is relatively straightforward to install if you already have a working Python and SciPy\n",
    "environment. You must also have an installation of Theano or TensorFlow on your system.\n",
    "Keras can be installed easily using pip, as follows:\n",
    "###### sudo pip install keras\n",
    "\n",
    "You can check your version of Keras on the command line using the following script:\n",
    "###### python -c \"import keras; print keras.__version__\"\n",
    "\n",
    "You can upgrade your installation of Keras using the same method:\n",
    "###### sudo pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Theano and TensorFlow Backends for Keras\n",
    "Keras is a lightweight API and rather than providing an implementation of the required\n",
    "mathematical operations needed for deep learning it provides a consistent interface to efficient\n",
    "numerical libraries called backends. Assuming you have both Theano and TensorFlow installed,\n",
    "you can configure the backend used by Keras. The easiest way is by adding or editing the Keras\n",
    "configuration file in your home directory:\n",
    "##### ~/.keras/keras.json\n",
    "\n",
    "Which has the format:\n",
    "```\n",
    "{\n",
    "\"image_dim_ordering\": \"th\",\n",
    "\"epsilon\": 1e-07,\n",
    "\"floatx\": \"float32\",\n",
    "\"backend\": \"theano\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this configuration file you can change the backend property from theano (the default) to\n",
    "tensorflow. Keras will then use the configuration the next time it is run. You can confirm the\n",
    "backend used by Keras using the following script on the command line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "!python -c \"from keras import backend; print backend._BACKEND\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify the backend to use by Keras on the command line by specifying the\n",
    "KERAS_BACKEND environment variable, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "theano\n"
     ]
    }
   ],
   "source": [
    "!KERAS_BACKEND=theano python -c \"from keras import backend; print backend._BACKEND\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "!python -c \"from keras import backend; print backend._BACKEND\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Build Deep Learning Models with Keras\n",
    "The focus of Keras is the idea of a model. The main type of model is a sequence of layers called\n",
    "a Sequential which is a linear stack of layers. You create a Sequential and add layers to it\n",
    "in the order that you wish for the computation to be performed. Once defined, you compile\n",
    "the model which makes use of the underlying framework to optimize the computation to be\n",
    "performed by your model. In this you can specify the loss function and the optimizer to be used.\n",
    "\n",
    "Once compiled, the model must be fit to data. This can be done one batch of data at a\n",
    "time or by firing off the entire model training regime. This is where all the compute happens.\n",
    "Once trained, you can use your model to make predictions on new data. We can summarize the\n",
    "construction of deep learning models in Keras as follows:\n",
    "1. Define your model. Create a Sequential model and add configured layers.\n",
    "2. Compile your model. Specify loss function and optimizers and call the compile()\n",
    "function on the model.\n",
    "3. Fit your model. Train the model on a sample of data by calling the fit() function on\n",
    "the model.\n",
    "4. Make predictions. Use the model to generate predictions on new data by calling\n",
    "functions such as evaluate() or predict() on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Summary\n",
    "In this lesson you discovered the Keras Python library for deep learning research and development.\n",
    "You learned:\n",
    "1. Keras wraps both the TensorFlow and Theano libraries, abstracting their capabilities and\n",
    "hiding their complexity.\n",
    "2. Keras is designed for minimalism and modularity allowing you to very quickly define deep\n",
    "learning models.\n",
    "3. Keras deep learning models can be developed using an idiom of defining, compiling and\n",
    "fitting models that can then be evaluated or used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next\n",
    "You are now up to speed with the Python libraries for deep learning and gives you the capability to install, configure and use the Python\n",
    "deep learning libraries on your workstation. Next in\n",
    "Part II you will learn how to use the Keras API and develop your own neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Multilayer Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Crash Course In Multilayer Perceptrons\n",
    "Artificial neural networks are a fascinating area of study, although they can be intimidating\n",
    "when just getting started. There is a lot of specialized terminology used when describing the\n",
    "data structures and algorithms used in the field. In this lesson you will get a crash course in the\n",
    "terminology and processes used in the field of Multilayer Perceptron artificial neural networks.\n",
    "After completing this lesson you will know:\n",
    "1. The building blocks of neural networks including neurons, weights and activation functions.\n",
    "2. How the building blocks are used in layers to create networks.\n",
    "3. How networks are trained from example data.\n",
    "Let’s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Crash Course Overview\n",
    "We are going to cover a lot of ground in this lesson. Here is an idea of what is ahead:\n",
    "1. Multilayer Perceptrons.\n",
    "2. Neurons, Weights and Activations.\n",
    "3. Networks of Neurons.\n",
    "4. Training Networks.\n",
    "We will start off with an overview of Multilayer Perceptrons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Multilayer Perceptrons\n",
    "The field of artificial neural networks is often just called Neural Networks or Multilayer Percep-\n",
    "trons after perhaps the most useful type of neural network. A Perceptron is a single neuron\n",
    "model that was a precursor to larger neural networks. It is a field of study that investigates\n",
    "how simple models of biological brains can be used to solve difficult computational tasks like\n",
    "the predictive modeling tasks we see in machine learning. The goal is not to create realistic\n",
    "models of the brain, but instead to develop robust algorithms and data structures that we can\n",
    "use to model difficult problems.\n",
    "\n",
    "The power of neural networks come from their ability to learn the representation in your\n",
    "training data and how to best relate it to the output variable that you want to predict. In\n",
    "this sense neural networks learn a mapping. Mathematically, they are capable of learning\n",
    "any mapping function and have been proven to be a universal approximation algorithm. The\n",
    "predictive capability of neural networks comes from the hierarchical or multilayered structure of\n",
    "the networks. The data structure can pick out (learn to represent) features at different scales or\n",
    "resolutions and combine them into higher-order features. For example from lines, to collections\n",
    "of lines to shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Neurons\n",
    "The building block for neural networks are artificial neurons. These are simple computational\n",
    "units that have weighted input signals and produce an output signal using an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](neuron.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Neuron Weights\n",
    "You may be familiar with linear regression, in which case the weights on the inputs are very\n",
    "much like the coefficients used in a regression equation. Like linear regression, each neuron also\n",
    "has a bias which can be thought of as an input that always has the value 1.0 and it too must be\n",
    "weighted. For example, a neuron may have two inputs in which case it requires three weights.\n",
    "One for each input and one for the bias.\n",
    "\n",
    "Weights are often initialized to small random values, such as values in the range 0 to 0.3,\n",
    "although more complex initialization schemes can be used. Like linear regression, larger weights\n",
    "indicate increased complexity and fragility of the model. It is desirable to keep weights in the\n",
    "network small and regularization techniques can be used.\n",
    "\n",
    "### 4.4.2 Activation\n",
    "The weighted inputs are summed and passed through an activation function, sometimes called a\n",
    "transfer function. An activation function is a simple mapping of summed weighted input to the\n",
    "output of the neuron. It is called an activation function because it governs the threshold at\n",
    "which the neuron is activated and the strength of the output signal. Historically simple step\n",
    "activation functions were used where if the summed input was above a threshold, for example\n",
    "0.5, then the neuron would output a value of 1.0, otherwise it would output a 0.0.\n",
    "\n",
    "Traditionally nonlinear activation functions are used. This allows the network to combine\n",
    "the inputs in more complex ways and in turn provide a richer capability in the functions they\n",
    "can model. Nonlinear functions like the logistic function also called the sigmoid function were\n",
    "used that output a value between 0 and 1 with an s-shaped distribution, and the hyperbolic\n",
    "tangent function also called Tanh that outputs the same distribution over the range -1 to +1.\n",
    "More recently the rectifier activation function has been shown to provide better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Networks of Neurons\n",
    "Neurons are arranged into networks of neurons. A row of neurons is called a layer and one\n",
    "network can have multiple layers. The architecture of the neurons in the network is often called\n",
    "the network topology.\n",
    "\n",
    "![alt text](network.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Input or Visible Layers\n",
    "The bottom layer that takes input from your dataset is called the visible layer, because it is\n",
    "the exposed part of the network. Often a neural network is drawn with a visible layer with one\n",
    "neuron per input value or column in your dataset. These are not neurons as described above,\n",
    "but simply pass the input value though to the next layer.\n",
    "\n",
    "### 4.5.2 Hidden Layers\n",
    "Layers after the input layer are called hidden layers because they are not directly exposed to\n",
    "the input. The simplest network structure is to have a single neuron in the hidden layer that\n",
    "directly outputs the value. Given increases in computing power and efficient libraries, very deep\n",
    "neural networks can be constructed. Deep learning can refer to having many hidden layers in\n",
    "your neural network. They are deep because they would have been unimaginably slow to train\n",
    "historically, but may take seconds or minutes to train using modern techniques and hardware.\n",
    "\n",
    "### 4.5.3 Output Layer\n",
    "The final hidden layer is called the output layer and it is responsible for outputting a value\n",
    "or vector of values that correspond to the format required for the problem. The choice of\n",
    "activation function in the output layer is strongly constrained by the type of problem that you\n",
    "are modeling. For example:\n",
    "1. A regression problem may have a single output neuron and the neuron may have no\n",
    "activation function.\n",
    "2. A binary classification problem may have a single output neuron and use a sigmoid\n",
    "activation function to output a value between 0 and 1 to represent the probability of\n",
    "predicting a value for the primary class. This can be turned into a crisp class value by\n",
    "using a threshold of 0.5 and snap values less than the threshold to 0 otherwise to 1.\n",
    "3. A multiclass classification problem may have multiple neurons in the output layer, one for\n",
    "each class (e.g. three neurons for the three classes in the famous iris flowers classification\n",
    "problem). In this case a softmax activation function may be used to output a probability\n",
    "of the network predicting each of the class values. Selecting the output with the highest\n",
    "probability can be used to produce a crisp class classification value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 Training Networks\n",
    "Once configured, the neural network needs to be trained on your dataset.\n",
    "\n",
    "### 4.6.1 Data Preparation\n",
    "You must first prepare your data for training on a neural network. Data must be numerical, for\n",
    "example real values. If you have categorical data, such as a sex attribute with the values male\n",
    "and female, you can convert it to a real-valued representation called a one hot encoding. This\n",
    "is where one new column is added for each class value (two columns in the case of sex of male\n",
    "and female) and a 0 or 1 is added for each row depending on the class value for that row.\n",
    "This same one hot encoding can be used on the output variable in classification problems\n",
    "with more than one class. This would create a binary vector from a single column that would\n",
    "be easy to directly compare to the output of the neuron in the network’s output layer, that as\n",
    "described above, would output one value for each class. Neural networks require the input to be\n",
    "scaled in a consistent way. You can rescale it to the range between 0 and 1 called normalization.\n",
    "Another popular technique is to standardize it so that the distribution of each column has the\n",
    "mean of zero and the standard deviation of 1. Scaling also applies to image pixel data. Data\n",
    "such as words can be converted to integers, such as the frequency rank of the word in the dataset\n",
    "and other encoding techniques.\n",
    "\n",
    "### 4.6.2 Stochastic Gradient Descent\n",
    "The classical and still preferred training algorithm for neural networks is called stochastic\n",
    "gradient descent. This is where one row of data is exposed to the network at a time as input.\n",
    "The network processes the input upward activating neurons as it goes to finally produce an\n",
    "output value. This is called a forward pass on the network. It is the type of pass that is also\n",
    "used after the network is trained in order to make predictions on new data.\n",
    "The output of the network is compared to the expected output and an error is calculated.\n",
    "This error is then propagated back through the network, one layer at a time, and the weights\n",
    "are updated according to the amount that they contributed to the error. This clever bit of math\n",
    "is called the Back Propagation algorithm. The process is repeated for all of the examples in\n",
    "your training data. One round of updating the network for the entire training dataset is called\n",
    "an epoch. A network may be trained for tens, hundreds or many thousands of epochs.\n",
    "\n",
    "### 4.6.3 Weight Updates\n",
    "The weights in the network can be updated from the errors calculated for each training example\n",
    "and this is called online learning. It can result in fast but also chaotic changes to the network.\n",
    "\n",
    "Alternatively, the errors can be saved up across all of the training examples and the network\n",
    "can be updated at the end. This is called batch learning and is often more stable.\n",
    "Because datasets are so large and because of computational efficiencies, the size of the\n",
    "batch, the number of examples the network is shown before an update is often reduced to a\n",
    "small number, such as tens or hundreds of examples. The amount that weights are updated is\n",
    "controlled by a configuration parameter called the learning rate. It is also called the step size\n",
    "and controls the step or change made to network weights for a given error. Often small learning\n",
    "rates are used such as 0.1 or 0.01 or smaller. The update equation can be complemented with\n",
    "additional configuration terms that you can set.\n",
    "1. Momentum is a term that incorporates the properties from the previous weight update\n",
    "to allow the weights to continue to change in the same direction even when there is less\n",
    "error being calculated.\n",
    "2. Learning Rate Decay is used to decrease the learning rate over epochs to allow the\n",
    "network to make large changes to the weights at the beginning and smaller fine tuning\n",
    "changes later in the training schedule.\n",
    "\n",
    "### 4.6.4 Prediction\n",
    "Once a neural network has been trained it can be used to make predictions. You can make\n",
    "predictions on test or validation data in order to estimate the skill of the model on unseen data.\n",
    "You can also deploy it operationally and use it to make predictions continuously. The network\n",
    "topology and the final set of weights is all that you need to save from the model. Predictions\n",
    "are made by providing the input to the network and performing a forward-pass allowing it to\n",
    "generate an output that you can use as a prediction.\n",
    "\n",
    "### Summary\n",
    "In this lesson you discovered artificial neural networks for machine learning. You learned:\n",
    "1. How neural networks are not models of the brain but are instead computational models\n",
    "for solving complex machine learning problems.\n",
    "2. That neural networks are comprised of neurons that have weights and activation functions.\n",
    "3. The networks are organized into layers of neurons and are trained using stochastic gradient\n",
    "descent.\n",
    "4. That it is a good idea to prepare your data before training a neural network model.\n",
    "\n",
    "### Next\n",
    "You now know the basics of neural network models. In the next section you will develop your\n",
    "very first Multilayer Perceptron model in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
